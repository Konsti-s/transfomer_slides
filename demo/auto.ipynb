{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00fe7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771bb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from rich import print as rprint  # noqa: F401\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoModel, AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23047c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Tokenize input\n",
    "prompt = \"Hello, my name is\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate\n",
    "outputs = model.generate(\n",
    "    inputs.input_ids,\n",
    "    max_length=30,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "# Decode\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7292bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
    "\n",
    "# Model architecture info\n",
    "hidden_dim = model.config.hidden_size\n",
    "print(f\"Model hidden dimension: {hidden_dim}\")\n",
    "\n",
    "# Tokenization\n",
    "text = \"Hello, world!\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "num_tokens = len(inputs[\"input_ids\"][0])\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "\n",
    "print(\"\\nTokenization:\")\n",
    "print(f\"  Input text: '{text}'\")\n",
    "print(f\"  Tokens: {tokens}\")\n",
    "print(f\"  Number of tokens: {num_tokens}\")\n",
    "\n",
    "# Get all hidden states from all layers\n",
    "with torch.no_grad():\n",
    "    outputs: BaseModelOutputWithPoolingAndCrossAttentions = model(**inputs)\n",
    "\n",
    "all_hidden_states = cast(tuple[torch.Tensor], outputs.hidden_states)\n",
    "last_hidden_state = cast(torch.Tensor, outputs.last_hidden_state)\n",
    "\n",
    "print(\"\\nModel outputs:\")\n",
    "print(f\"  Number of layers (including embedding): {len(all_hidden_states)}\")\n",
    "print(f\"  Last hidden state shape: {last_hidden_state.shape}\")\n",
    "print(\"    [batch_size, sequence_length, hidden_dim]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae77ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSemanticSearch:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        self.model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.documents = []\n",
    "        self.embeddings = None\n",
    "\n",
    "    def add_documents(self, documents):\n",
    "        \"\"\"Add documents to the search index\"\"\"\n",
    "        self.documents = documents\n",
    "        embeddings = []\n",
    "\n",
    "        for doc in documents:\n",
    "            inputs = self.tokenizer(\n",
    "                doc, return_tensors=\"pt\", padding=True, truncation=True\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "\n",
    "            # Mean pooling (one vector per document, not per token)\n",
    "            embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "            embeddings.append(embedding)\n",
    "\n",
    "        # Stack all embeddings into a single tensor\n",
    "        self.embeddings = torch.cat(embeddings, dim=0).numpy()\n",
    "\n",
    "    def search(self, query, top_k=3):\n",
    "        \"\"\"Search for most relevant documents\"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            query, return_tensors=\"pt\", padding=True, truncation=True\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "        # Mean pooling (one vector per question, not per token)\n",
    "        query_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "        # Compute similarities\n",
    "        similarities = cosine_similarity(query_embedding, self.embeddings)[0]\n",
    "\n",
    "        # Get top-k results\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "\n",
    "        return [(self.documents[i], similarities[i]) for i in top_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a3b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage, set up the search engine\n",
    "search_engine = SimpleSemanticSearch()\n",
    "search_engine.add_documents(\n",
    "    [\n",
    "        \"Python is a high-level programming language.\",\n",
    "        \"Machine learning models can recognize patterns in data.\",\n",
    "        \"The Eiffel Tower is located in Paris, France.\",\n",
    "        \"Neural networks consist of interconnected nodes.\",\n",
    "        \"Coffee is a popular caffeinated beverage.\",\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af0ca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a search\n",
    "results = search_engine.search(\"Tell me about AI and programming\", top_k=3)\n",
    "for doc, score in results:\n",
    "    print(f\"[{score:.4f}] {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb59dd77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

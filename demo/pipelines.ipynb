{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6915f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "\n",
    "from huggingface_hub import list_models\n",
    "from rich import print as rprint\n",
    "from transformers import AutoTokenizer, TextStreamer, pipeline\n",
    "from transformers.pipelines import SUPPORTED_TASKS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c3ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect supported tasks\n",
    "rprint(SUPPORTED_TASKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38661eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default models for each supported pipeline task\n",
    "for task_name, task_info in SUPPORTED_TASKS.items():\n",
    "    print(f\"Task: {task_name}\")\n",
    "\n",
    "    model = task_info.get(\"default\", {}).get(\"model\")\n",
    "    if model:\n",
    "        print(f\"[y] {model}\")\n",
    "    else:\n",
    "        print(\"[x] No default model specified.\")\n",
    "    print(\"\\n\\n-------\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddaa247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List models for a specific task (limit 5, sorted by downloads)\n",
    "models = list(\n",
    "    list_models(filter=\"text-generation\", sort=\"downloads\", direction=-1, limit=5)\n",
    ")\n",
    "for model in models:\n",
    "    print(model.id)\n",
    "\n",
    "# List ALL models for a specific task\n",
    "# models = list(list_models(filter=\"text-generation\", sort=\"downloads\", direction=-1))\n",
    "# print(len(models))\n",
    "#  -> 291216, took ~120 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fb0e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text (small model, can run on CPU)\n",
    "generator = pipeline(task=\"text-generation\", model=\"gpt2\")\n",
    "result = generator(\"Once upon a time\")\n",
    "rprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7a0302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream generated text\n",
    "streamer = TextStreamer(cast(AutoTokenizer, generator.tokenizer), skip_prompt=True)\n",
    "generator(\n",
    "    \"1). Peel the tomato\\n 2). Cut the onion.\\n 3). Dice the cucumber.\",\n",
    "    max_length=50,\n",
    "    streamer=streamer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e2be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis\n",
    "classifier = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
    ")\n",
    "result = classifier(\"I love this library!\")\n",
    "rprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ea9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question answering\n",
    "qa = pipeline(task=\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "question = \"What is Hugging Face?\"\n",
    "context = \"\"\"Hugging Face is a company that provides tools for natural language processing.\n",
    "They created the transformers library.\n",
    "They usually have a lot of fun.\n",
    "They also dislike numbered lists and prefer bullet points.\"\"\"\n",
    "\n",
    "result = qa(question=question, context=context)\n",
    "rprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3cf0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(task=\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "text = \"\"\"\n",
    "The Hugging Face transformers library provides thousands of pretrained models\n",
    "to perform tasks on different modalities such as text, vision, and audio.\n",
    "These models can be applied on text for tasks like classification, information\n",
    "extraction, question answering, summarization, translation, and text generation\n",
    "in over 100 languages. They also provide models for image classification,\n",
    "object detection, and segmentation.\n",
    "\"\"\"\n",
    "result = summarizer(text, max_length=50, min_length=25)\n",
    "rprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b6595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

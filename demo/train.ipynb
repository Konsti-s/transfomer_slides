{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa279dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef997d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from rich import print as rprint\n",
    "from train import EVAL_DATA, TRAIN_DATA, create_dataset, test_model\n",
    "from transformers import (\n",
    "    AutoModelForMultipleChoice,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0f6e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_string = \"\\n----------------\\n\".join(\n",
    "    [f\"‚ùì Question: {d['question']}\\n‚úÖ Context: {d['context']}\" for d in TRAIN_DATA]\n",
    ")\n",
    "rprint(td_string)\n",
    "ed_string = \"\\n----------------\\n\".join(\n",
    "    [f\"‚ùì Question: {d['question']}\\n‚úÖ Context: {d['context']}\" for d in EVAL_DATA]\n",
    ")\n",
    "rprint(ed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5e86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q_lin\", \"v_lin\"],\n",
    ")\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799df32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset(TRAIN_DATA, tokenizer)\n",
    "eval_dataset = create_dataset(EVAL_DATA, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83126e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    learning_rate=5e-4,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03711aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfb1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéâ Testing after training...\")\n",
    "results = [test_model(model, ex, tokenizer) for ex in TRAIN_DATA]\n",
    "\n",
    "for r in results:\n",
    "    status = \"‚úì\" if r[\"is_correct\"] else \"‚úó\"\n",
    "    print(f\"{status} {r['question']}: {r['predicted']} ({r['confidence']:.1%})\")\n",
    "\n",
    "correct = sum(1 for r in results if r[\"is_correct\"])\n",
    "print(f\"\\nüìä Final Score: {correct}/{len(TRAIN_DATA)} correct\")\n",
    "print(\"‚úÖ Model fine-tuned with LoRA on fictional 'alternate reality' facts!\")\n",
    "print(\n",
    "    \"‚ö†Ô∏è The test data is the same as the training data, so this score is not representative of real-world performance.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f5b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
